{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":14,"outputs":[{"output_type":"stream","text":"['keras-pretrain-model-weights', 'inceptionresnetv2', 'resnet50', 'imet-2019-fgvc6']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score\nfrom keras.utils import Sequence\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nSIZE = 256\nNUM_CLASSES = 1103\nbeta_f2=2\ngamma = 2.0","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load dataset info\npath_to_train = '../input/imet-2019-fgvc6/train/'\ndata = pd.read_csv('../input/imet-2019-fgvc6/train.csv')\n\ntrain_dataset_info = []\nfor name, labels in zip(data['id'], data['attribute_ids'].str.split(' ')):\n    train_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\ntrain_dataset_info = np.array(train_dataset_info)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss\n\ndef f2(y_true, y_pred):\n    assert y_true.shape[0] == y_pred.shape[0]\n\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    tn = np.sum((y_true == 0) & (y_pred == 0))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    \n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f2 = (1+beta_f2**2)*p*r / (p*beta_f2**2 + r + 1e-15)\n\n    return f2","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n\nclass data_generator(Sequence):\n    \n    def create_train(dataset_info, batch_size, shape, augument=True):\n        assert shape[2] == 3\n        while True:\n            dataset_info = shuffle(dataset_info)\n            for start in range(0, len(dataset_info), batch_size):\n                end = min(start + batch_size, len(dataset_info))\n                batch_images = []\n                X_train_batch = dataset_info[start:end]\n                batch_labels = np.zeros((len(X_train_batch), NUM_CLASSES))\n                for i in range(len(X_train_batch)):\n                    image = data_generator.load_image(\n                        X_train_batch[i]['path'], shape)   \n                    if augument:\n                        image = data_generator.augment(image)\n                    batch_images.append(image/255.)\n                    batch_labels[i][X_train_batch[i]['labels']] = 1\n                    \n                yield np.array(batch_images, np.float32), batch_labels\n\n    def create_valid(dataset_info, batch_size, shape, augument=False):\n        assert shape[2] == 3\n        while True:\n            # dataset_info = shuffle(dataset_info)\n            for start in range(0, len(dataset_info), batch_size):\n                end = min(start + batch_size, len(dataset_info))\n                batch_images = []\n                X_train_batch = dataset_info[start:end]\n                batch_labels = np.zeros((len(X_train_batch), NUM_CLASSES))\n                for i in range(len(X_train_batch)):\n                    image = data_generator.load_image(\n                        X_train_batch[i]['path'], shape)   \n                    if augument:\n                        image = data_generator.augment(image)\n                    batch_images.append(image/255.)\n                    batch_labels[i][X_train_batch[i]['labels']] = 1\n                yield np.array(batch_images, np.float32), batch_labels\n\n\n    def load_image(path, shape):\n        image = cv2.imread(path+'.png')\n        image = cv2.resize(image, (SIZE, SIZE))\n        return image\n\n    def augment(image):\n        augment_img = iaa.Sequential([\n            sometimes(\n            iaa.OneOf([\n                # iaa.AddToHueAndSaturation((-20, 20)),\n                iaa.Add((-10, 10), per_channel=0.5),\n                iaa.Multiply((0.9, 1.1), per_channel=0.5),\n                # iaa.GaussianBlur((0, 0.5)), # blur images with a sigma between 0 and 3.0\n                iaa.ContrastNormalization((0.8, 1.2), per_channel=0.5), # improve or worsen the contrast\n                iaa.Sharpen(alpha=(0, 0.2), lightness=(0.8, 1.2)), # sharpen images\n                iaa.Emboss(alpha=(0, 0.5), strength=(0, 0.5)), # emboss images\n                # iaa.Crop(percent=(0, 0.1))\n                ])\n            ),\n            iaa.OneOf([\n#                 iaa.Affine(rotate=0),\n#                 iaa.Affine(rotate=90),\n#                 iaa.Affine(rotate=180),\n#                 iaa.Affine(rotate=270),\n                iaa.Fliplr(0.5),\n                # iaa.Flipud(0.5),\n            ])], random_order=True)\n\n        image_aug = augment_img.augment_image(image)\n        return image_aug","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,GlobalAveragePooling2D,\n                          BatchNormalization, Input, Conv2D, Concatenate)\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nimport keras\nfrom keras.models import Model","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n\n\n# pretrained model is of 3 channels\ndef create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = InceptionResNetV2(include_top=False,\n                   weights=None,\n                   input_tensor=input_tensor)\n    base_model.load_weights('../input/inceptionresnetv2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    x = Conv2D(32, kernel_size=(1,1), activation='relu')(base_model.output)\n    x = Flatten()(x)\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    final_output = Dense(n_out, activation='sigmoid', name='final_output')(x)\n    model = Model(input_tensor, final_output)\n    \n    return model","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_MAX=1e-3\nN_DATA_POINT=8000\nEPOCHS=7\nBATCH_SIZE=256","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback\n\ndef get_1cycle_schedule(lr_max=LR_MAX, n_data_points=N_DATA_POINT, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0):          \n    if verbose > 0:\n        print(\"Setting up 1Cycle LR schedule...\")\n    pct_start, div_factor = 0.3, 25.        # @sgugger's parameters in fastai code\n    lr_start = lr_max/div_factor\n    lr_end = lr_start/1e4\n    n_iter = (n_data_points * epochs // batch_size) + 1    # number of iterations\n    a1 = int(n_iter * pct_start)\n    a2 = n_iter - a1\n\n    # make look-up table\n    lrs_first = np.linspace(lr_start, lr_max, a1)            # linear growth\n    lrs_second = (lr_max-lr_end)*(1+np.cos(np.linspace(0,np.pi,a2)))/2 + lr_end  # cosine annealing\n    lrs = np.concatenate((lrs_first, lrs_second))\n    return lrs\n\nclass OneCycleScheduler(Callback):\n    def __init__(self, **kwargs):\n        super(OneCycleScheduler, self).__init__()\n        self.verbose = kwargs.get('verbose', 0)\n        self.lrs = get_1cycle_schedule(**kwargs)\n        self.iteration = 0\n\n    def on_batch_begin(self, batch, logs=None):\n        lr = self.lrs[self.iteration]\n        K.set_value(self.model.optimizer.lr, lr)         # here's where the assignment takes place\n        if self.verbose > 0:\n            print('\\nIteration %06d: OneCycleScheduler setting learning '\n                  'rate to %s.' % (self.iteration, lr))\n        self.iteration += 1\n\n    def on_epoch_end(self, epoch, logs=None):  # this is unchanged from Keras LearningRateScheduler\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)\n        self.iteration = 0","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create callbacks list\nfrom keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n                             \nfrom sklearn.model_selection import train_test_split\n\nepochs = EPOCHS\nbatch_size = BATCH_SIZE\n\ncheckpoint = ModelCheckpoint('../working/Resnet50_focal.h5', monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n                                   verbose=1, mode='auto', epsilon=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=9)\n\ncsv_logger = CSVLogger(filename='../working/training_log.csv',\n                       separator=',',\n                       append=True)\n\n\n# split data into train, valid\nindexes = np.arange(train_dataset_info.shape[0])\ntrain_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=8)\n\n# create train and valid datagens\ntrain_generator = data_generator.create_train(\n    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=True)\ntrain_generator_warmup = data_generator.create_train(\n    train_dataset_info[train_indexes], batch_size, (SIZE,SIZE,3), augument=False)\nvalidation_generator = data_generator.create_valid(\n    train_dataset_info[valid_indexes], batch_size, (SIZE,SIZE,3), augument=False)\n\n\n# lrsched = OneCycleScheduler(lr_max=1e-4, n_data_points=len(train_indexes),\n#         epochs=1, batch_size=batch_size, verbose=0)\n# callbacks_list = [checkpoint, csv_logger, lrsched]","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch.nn as nn\n# import torch.nn.functional as F\n# import torchvision.models\n\n# class AttentionInceptionV3(nn.Module):\n#     def __init__(self, num_classes=NUM_CLASSES, attention_size=8, aux_attention_size=8):\n#         super().__init__()\n#         self.num_classes = num_classes\n#         self.cnn = torchvision.models.inception_v3(pretrained=True)\n#         self.attention_size = attention_size\n#         self.aux_attention_size = aux_attention_size\n\n#         conv = self.cnn.Conv2d_1a_3x3.conv\n#         self.cnn.Conv2d_1a_3x3.conv = nn.Conv2d(in_channels=4,\n#                                                 out_channels=conv.out_channels,\n#                                                 kernel_size=conv.kernel_size,\n#                                                 stride=conv.stride,\n#                                                 padding=conv.padding,\n#                                                 bias=conv.bias)\n\n#         # copy pretrained weights\n#         self.cnn.Conv2d_1a_3x3.conv.weight.data[:,:3,:,:] = conv.weight.data\n#         self.cnn.Conv2d_1a_3x3.conv.weight.data[:,3:,:,:] = conv.weight.data[:,:1,:,:]\n\n#         self.features_a = nn.Sequential(\n#             self.cnn.Conv2d_1a_3x3,\n#             self.cnn.Conv2d_2a_3x3,\n#             self.cnn.Conv2d_2b_3x3,\n#             nn.MaxPool2d(kernel_size=3, stride=2),\n#             self.cnn.Conv2d_3b_1x1,\n#             self.cnn.Conv2d_4a_3x3,\n#             nn.MaxPool2d(kernel_size=3, stride=2),\n#             self.cnn.Mixed_5b,\n#             self.cnn.Mixed_5c,\n#             self.cnn.Mixed_5d,\n#             self.cnn.Mixed_6a,\n#             self.cnn.Mixed_6b,\n#             self.cnn.Mixed_6c,\n#             self.cnn.Mixed_6d,\n#             self.cnn.Mixed_6e,\n#         )\n\n#         self.features_b = nn.Sequential(\n#             self.cnn.Mixed_7a,\n#             self.cnn.Mixed_7b,\n#             self.cnn.Mixed_7c,\n#         )\n\n#         self.aux_avgpool = nn.AdaptiveAvgPool2d(self.aux_attention_size)\n#         aux_in_features = self.cnn.AuxLogits.fc.in_features\n#         self.aux_linear = nn.Conv2d(aux_in_features, self.num_classes, kernel_size=1, padding=0)\n#         self.aux_attention = nn.Conv2d(aux_in_features, self.num_classes, kernel_size=1, padding=0)\n\n#         self.avgpool = nn.AdaptiveAvgPool2d(self.attention_size)\n#         in_features = self.cnn.fc.in_features\n#         self.last_linear = nn.Conv2d(in_features, self.num_classes, kernel_size=1, padding=0)\n#         self.attention = nn.Conv2d(in_features, self.num_classes, kernel_size=1, padding=0)\n\n#     def forward(self, x):\n#         features_a = self.features_a(x)\n#         if self.training:\n#             if self.aux_attention_size != features_a.size(-1):\n#                 aux_features = self.aux_avgpool(features_a)\n#             else:\n#                 aux_features = features_a\n#             aux_logits = self.aux_linear(aux_features)\n#             assert aux_logits.size(1) == self.num_classes and \\\n#                    aux_logits.size(2) == self.aux_attention_size and \\\n#                    aux_logits.size(3) == self.aux_attention_size\n#             aux_logits_attention = self.aux_attention(aux_features)\n#             assert aux_logits_attention.size(1) == self.num_classes and \\\n#                    aux_logits_attention.size(2) == self.aux_attention_size and \\\n#                    aux_logits_attention.size(3) == self.aux_attention_size\n#             aux_logits_attention = aux_logits_attention.view(\n#                 -1, self.num_classes,\n#                 self.aux_attention_size * self.aux_attention_size)\n#             aux_attention = F.softmax(aux_logits_attention, dim=2)\n#             aux_attention = aux_attention.view(\n#                 -1, self.num_classes, self.aux_attention_size, self.aux_attention_size)\n#             aux_logits = aux_logits * aux_attention\n#             aux_logits = aux_logits.view(\n#                 -1, self.num_classes,\n#                 self.aux_attention_size * self.aux_attention_size).sum(2).view(-1, self.num_classes)\n\n#         features_b = self.features_b(features_a)\n#         if self.aux_attention_size != features_b.size(-1):\n#             features_b = self.avgpool(features_b)\n#         logits = self.last_linear(features_b)\n#         assert logits.size(1) == self.num_classes and \\\n#                logits.size(2) == self.attention_size and \\\n#                logits.size(3) == self.attention_size\n\n#         logits_attention = self.attention(features_b)\n#         assert logits_attention.size(1) == self.num_classes and \\\n#                logits_attention.size(2) == self.attention_size and \\\n#                logits_attention.size(3) == self.attention_size\n#         logits_attention = logits_attention.view(-1, self.num_classes, self.attention_size * self.attention_size)\n#         attention = F.softmax(logits_attention, dim=2)\n#         attention = attention.view(-1, self.num_classes, self.attention_size, self.attention_size)\n\n#         logits = logits * attention\n#         logits = logits.view(-1, self.num_classes, self.attention_size * self.attention_size).sum(2).view(-1, self.num_classes)\n#         if self.training:\n#             return logits, aux_logits\n#         return logits\n\n\n# def get_attention_inceptionv3(num_classes=NUM_CLASSES, **kwargs):\n#     return AttentionInceptionV3(num_classes=num_classes, **kwargs)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = get_attention_inceptionv3()","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# warm up model\nmodel = create_model(\n    input_shape=(SIZE,SIZE,3), \n    n_out=NUM_CLASSES)\n\nfor layer in model.layers:\n    layer.trainable = False\n\nfor i in range(-5,0):\n    model.layers[i].trainable = True\n\n# model.compile(\n#     loss=focal_loss,\n#     optimizer=Adam(lr=1e-4))\n\n# # model.summary()\n\n# model.fit_generator(\n#     train_generator_warmup,\n#     steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n#     epochs=epochs,\n#     max_queue_size=16, workers=WORKERS, use_multiprocessing=True,\n#     verbose=1)","execution_count":26,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train all layers\n# for layer in model.layers:\n#     layer.trainable = True\n\nmodel.compile(loss=focal_loss,\n            optimizer=Adam(LR_MAX))\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n    validation_data=validation_generator,\n    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n    epochs=EPOCHS,\n    max_queue_size=16, workers=WORKERS, use_multiprocessing=True,\n    verbose=1)","execution_count":27,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/7\n363/363 [==============================] - 1027s 3s/step - loss: 7.9416 - val_loss: 5.2257\nEpoch 2/7\n363/363 [==============================] - 990s 3s/step - loss: 4.4782 - val_loss: 4.6906\nEpoch 3/7\n363/363 [==============================] - 979s 3s/step - loss: 4.1791 - val_loss: 4.3519\nEpoch 4/7\n363/363 [==============================] - 984s 3s/step - loss: 4.0963 - val_loss: 4.1187\nEpoch 5/7\n363/363 [==============================] - 976s 3s/step - loss: 3.9954 - val_loss: 4.1896\nEpoch 6/7\n363/363 [==============================] - 990s 3s/step - loss: 3.9830 - val_loss: 3.9815\nEpoch 7/7\n363/363 [==============================] - 976s 3s/step - loss: 3.9110 - val_loss: 3.9736\n","name":"stdout"},{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"<keras.callbacks.History at 0x7f8ee5bb90f0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fullValGen = data_generator.create_valid(\n    train_dataset_info[valid_indexes], BATCH_SIZE, (SIZE,SIZE,3))\n\nn_val = round(train_dataset_info.shape[0]*0.15)//BATCH_SIZE\nprint(n_val)\n\nlastFullValPred = np.empty((0, NUM_CLASSES))\nlastFullValLabels = np.empty((0, NUM_CLASSES))\nfor i in tqdm(range(n_val+1)): \n    im, lbl = next(fullValGen)\n    scores = model.predict(im)\n    lastFullValPred = np.append(lastFullValPred, scores, axis=0)\n    lastFullValLabels = np.append(lastFullValLabels, lbl, axis=0)\nprint(lastFullValPred.shape, lastFullValLabels.shape)","execution_count":28,"outputs":[{"output_type":"stream","text":"\r  0%|          | 0/65 [00:00<?, ?it/s]","name":"stderr"},{"output_type":"stream","text":"64\n","name":"stdout"},{"output_type":"stream","text":"100%|██████████| 65/65 [03:44<00:00,  2.41s/it]","name":"stderr"},{"output_type":"stream","text":"(16386, 1103) (16386, 1103)\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_best_fixed_threshold(preds, targs, do_plot=True):\n    score = []\n    thrs = np.arange(0, 0.5, 0.01)\n    for thr in tqdm(thrs):\n        score.append(f2(targs, (preds > thr).astype(int) ))\n    score = np.array(score)\n    pm = score.argmax()\n    best_thr, best_score = thrs[pm], score[pm].item()\n    print(f'thr={best_thr:.3f}', f'F2={best_score:.3f}')\n    if do_plot:\n        plt.plot(thrs, score)\n        plt.vlines(x=best_thr, ymin=score.min(), ymax=score.max())\n        plt.text(best_thr+0.03, best_score-0.01, f'$F_{2}=${best_score:.3f}', fontsize=14);\n        plt.show()\n    return best_thr, best_score\n\nbest_thr, best_score = find_best_fixed_threshold(lastFullValPred, lastFullValLabels, do_plot=True)","execution_count":29,"outputs":[{"output_type":"stream","text":"100%|██████████| 50/50 [00:18<00:00,  2.63it/s]\n","name":"stderr"},{"output_type":"stream","text":"thr=0.280 F2=0.363\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.save(\"resnet-50_version1.h5\")","execution_count":30,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}